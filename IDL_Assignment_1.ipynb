{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Group Members\n",
        "1. Preeti Singh\n",
        "2. Saikat Mitra\n",
        "3. Shardul Kulkarni"
      ],
      "metadata": {
        "id": "eb2wMY9SXuYv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGFJ253-i5KP",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        " import os\n",
        " os.chdir(\"/content/drive/MyDrive/Colab Notebooks/IDL/Ass1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoieuECoHkei",
        "outputId": "87cc0efb-0980-4a90-9cf8-38ece876fc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOO6qi2cjYTI",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from datasets import MNISTDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp1YQ0ERjhWA",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "f6d1fae6-3645-40f2-916f-1b5fe5d6550d"
      },
      "source": [
        "# mnist is a api or link to MNIST dataset - keras.api._v2.keras.datasets.mnist\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() #Splitting the dataset into training & Testing set\n",
        "\n",
        "# we can look at any of the images and the corresponding labels\n",
        "# say, image no. 155\n",
        "plt.imshow(train_images[155], cmap=\"Greys_r\")\n",
        "plt.show()\n",
        "print(train_labels[155])\n",
        "train_images.reshape(-1,2)\n",
        "# images are \"flattened\" into vectors to avoid heavy memory usage\n",
        "data = MNISTDataset(train_images.reshape([-1, 28*28]), train_labels, \n",
        "                    test_images.reshape([-1, 28*28]), test_labels,\n",
        "                    batch_size=128)\n",
        "print(train_images[155].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "(28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here is an attempt at illustrating what flattening looks like\n",
        "reshaped = train_images[155].reshape((-1, 28*28))\n",
        "plt.figure(figsize=(17, 5))\n",
        "plt.pcolormesh(reshaped, cmap=\"Greys_r\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_y6U9BC-ermh",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "9c30cc5c-a789-468a-aaf5-50ab0f1a8eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1224x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYv32fO0iBSQ",
        "outputId": "3c026108-7dd6-4776-efba-380d6baa22de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e-xm7xnjoAB",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Weights and bias initialization\n",
        "w0 = tf.Variable(np.random.uniform(size=(784,256), low=-0.1, high=0.1).astype(np.float32))\n",
        "b0 = tf.Variable(np.random.uniform(size = 256, low=-0.1, high=0.1).astype(np.float32))\n",
        "w1 = tf.Variable(np.random.uniform(size =(256,256), low=-0.1, high=0.1).astype(np.float32))\n",
        "b1 = tf.Variable(np.random.uniform(size = 256, low=-0.1, high=0.1).astype(np.float32))\n",
        "out_w = tf.Variable(np.random.uniform(size =(256,10), low=-0.1, high=0.1).astype(np.float32))\n",
        "out_b = tf.Variable(np.random.uniform(size = 10, low=-0.1, high=0.1).astype(np.float32))\n",
        "\n",
        "# Using Activation function RELU to overcome Vanishing Gradient Problem \n",
        "def model(inputs):\n",
        "  # Input Layer \n",
        "  layer_1 = tf.add(tf.matmul(inputs, w0), b0) \n",
        "  layer_1 = tf.nn.relu(layer_1)\n",
        "  # Hidden Layer \n",
        "  layer_2 = tf.add(tf.matmul(layer_1, w1), b1)\n",
        "  layer_2 = tf.nn.relu(layer_2)\n",
        "  # Output Layer\n",
        "  out_layer = tf.matmul(layer_2, out_w) + out_b\n",
        "  return out_layer\n",
        "    \n",
        "train_steps = 4000\n",
        "learning_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWwZsraTj2fx",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0811d55d-b643-48ea-cd18-281e648cc200"
      },
      "source": [
        "# training loop\n",
        "for step in range(train_steps+1):\n",
        "    image_batch, label_batch = data.next_batch()\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(image_batch)\n",
        "\n",
        "      xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=label_batch))\n",
        "         \n",
        "      grads = tape.gradient(xent, [w0, b0, w1, b1, out_w, out_b])\n",
        "\n",
        "      w0.assign_sub(learning_rate * grads[0])\n",
        "      b0.assign_sub(learning_rate * grads[1])\n",
        "      w1.assign_sub(learning_rate * grads[2])\n",
        "      b1.assign_sub(learning_rate * grads[3])\n",
        "      out_w.assign_sub(learning_rate * grads[4])\n",
        "      out_b.assign_sub(learning_rate * grads[5])\n",
        "    \n",
        "    # every so often we print loss/accuracy\n",
        "    if not step % 100:\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, label_batch),\n",
        "                             tf.float32))\n",
        "        print(\"Step {}. Batch loss: {} Batch accuracy: {}\".format(step+1, xent, acc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1. Batch loss: 2.298374652862549 Batch accuracy: 0.09375\n",
            "Step 101. Batch loss: 0.36649906635284424 Batch accuracy: 0.9140625\n",
            "Step 201. Batch loss: 0.4495994746685028 Batch accuracy: 0.828125\n",
            "Step 301. Batch loss: 0.17709293961524963 Batch accuracy: 0.9609375\n",
            "Step 401. Batch loss: 0.2060117870569229 Batch accuracy: 0.953125\n",
            "Starting new epoch...\n",
            "Step 501. Batch loss: 0.22643499076366425 Batch accuracy: 0.953125\n",
            "Step 601. Batch loss: 0.2662007212638855 Batch accuracy: 0.875\n",
            "Step 701. Batch loss: 0.19697163999080658 Batch accuracy: 0.9453125\n",
            "Step 801. Batch loss: 0.12442759424448013 Batch accuracy: 0.96875\n",
            "Step 901. Batch loss: 0.20644298195838928 Batch accuracy: 0.96875\n",
            "Starting new epoch...\n",
            "Step 1001. Batch loss: 0.14273446798324585 Batch accuracy: 0.9453125\n",
            "Step 1101. Batch loss: 0.08009163290262222 Batch accuracy: 0.9765625\n",
            "Step 1201. Batch loss: 0.0819505900144577 Batch accuracy: 0.984375\n",
            "Step 1301. Batch loss: 0.241347998380661 Batch accuracy: 0.9140625\n",
            "Step 1401. Batch loss: 0.24938951432704926 Batch accuracy: 0.9296875\n",
            "Starting new epoch...\n",
            "Step 1501. Batch loss: 0.1375667005777359 Batch accuracy: 0.9453125\n",
            "Step 1601. Batch loss: 0.14200621843338013 Batch accuracy: 0.953125\n",
            "Step 1701. Batch loss: 0.2028384804725647 Batch accuracy: 0.9609375\n",
            "Step 1801. Batch loss: 0.08033826947212219 Batch accuracy: 0.96875\n",
            "Starting new epoch...\n",
            "Step 1901. Batch loss: 0.13134217262268066 Batch accuracy: 0.953125\n",
            "Step 2001. Batch loss: 0.1520358920097351 Batch accuracy: 0.953125\n",
            "Step 2101. Batch loss: 0.09425323456525803 Batch accuracy: 0.9609375\n",
            "Step 2201. Batch loss: 0.1661980003118515 Batch accuracy: 0.9453125\n",
            "Step 2301. Batch loss: 0.09483038634061813 Batch accuracy: 0.9765625\n",
            "Starting new epoch...\n",
            "Step 2401. Batch loss: 0.1891927272081375 Batch accuracy: 0.9375\n",
            "Step 2501. Batch loss: 0.1013319119811058 Batch accuracy: 0.9765625\n",
            "Step 2601. Batch loss: 0.11922086775302887 Batch accuracy: 0.96875\n",
            "Step 2701. Batch loss: 0.0725027322769165 Batch accuracy: 0.9765625\n",
            "Step 2801. Batch loss: 0.10952933877706528 Batch accuracy: 0.9609375\n",
            "Starting new epoch...\n",
            "Step 2901. Batch loss: 0.06610555946826935 Batch accuracy: 0.9765625\n",
            "Step 3001. Batch loss: 0.042463988065719604 Batch accuracy: 1.0\n",
            "Step 3101. Batch loss: 0.026928823441267014 Batch accuracy: 1.0\n",
            "Step 3201. Batch loss: 0.09999726712703705 Batch accuracy: 0.9609375\n",
            "Starting new epoch...\n",
            "Step 3301. Batch loss: 0.024856023490428925 Batch accuracy: 1.0\n",
            "Step 3401. Batch loss: 0.06268977373838425 Batch accuracy: 0.9765625\n",
            "Step 3501. Batch loss: 0.03293394297361374 Batch accuracy: 1.0\n",
            "Step 3601. Batch loss: 0.04213574156165123 Batch accuracy: 0.984375\n",
            "Step 3701. Batch loss: 0.07098152488470078 Batch accuracy: 0.9921875\n",
            "Starting new epoch...\n",
            "Step 3801. Batch loss: 0.03562481701374054 Batch accuracy: 0.9765625\n",
            "Step 3901. Batch loss: 0.07968471944332123 Batch accuracy: 0.9765625\n",
            "Step 4001. Batch loss: 0.06749832630157471 Batch accuracy: 0.9765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGSRvdL5j6iz",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a743fb5d-b133-4a9a-cf48-9032a1914318"
      },
      "source": [
        "test_preds = tf.argmax(model(data.test_data), axis=1,\n",
        "                       output_type=tf.int32)\n",
        "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels),\n",
        "                             tf.float32))\n",
        "print(\"Test accuracy: {}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9745000004768372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observations\n",
        "\n",
        "1. When learning rate is changed from **0.1** to **0.01** then Accruracy is changed from **96.87** to **90.89**, because with lower learning rate model converges slowly.\n",
        "\n",
        "2. When we train the model with more training steps(EPOCH), the test accuracy is increased."
      ],
      "metadata": {
        "id": "9S-CfXjGirVT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dSQ9rwT0q1ag"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}